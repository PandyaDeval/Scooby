{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\dharmik\\anaconda3\\lib\\site-packages (3.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import speech_recognition as sr\n",
    "import speech\n",
    "from os import path\n",
    "from pywinauto import Desktop, Application\n",
    "from pywinauto.keyboard import SendKeys, KeySequenceError\n",
    "#from pywinauto.timings import wait_until\n",
    "from pywinauto import mouse\n",
    "import re, time, math\n",
    "import spacy\n",
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pytesseract\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DHARMIK\\Anaconda3\\lib\\site-packages\\msgpack_numpy.py:184: PendingDeprecationWarning: encoding is deprecated, Use raw=False instead.\n",
      "  return _unpackb(packed, **kwargs)\n",
      "C:\\Users\\DHARMIK\\Anaconda3\\lib\\site-packages\\msgpack_numpy.py:184: PendingDeprecationWarning: encoding is deprecated, Use raw=False instead.\n",
      "  return _unpackb(packed, **kwargs)\n",
      "C:\\Users\\DHARMIK\\Anaconda3\\lib\\site-packages\\msgpack_numpy.py:184: PendingDeprecationWarning: encoding is deprecated, Use raw=False instead.\n",
      "  return _unpackb(packed, **kwargs)\n",
      "C:\\Users\\DHARMIK\\Anaconda3\\lib\\site-packages\\msgpack_numpy.py:184: PendingDeprecationWarning: encoding is deprecated, Use raw=False instead.\n",
      "  return _unpackb(packed, **kwargs)\n",
      "C:\\Users\\DHARMIK\\Anaconda3\\lib\\site-packages\\msgpack_numpy.py:184: PendingDeprecationWarning: encoding is deprecated, Use raw=False instead.\n",
      "  return _unpackb(packed, **kwargs)\n",
      "C:\\Users\\DHARMIK\\Anaconda3\\lib\\site-packages\\msgpack_numpy.py:184: PendingDeprecationWarning: encoding is deprecated, Use raw=False instead.\n",
      "  return _unpackb(packed, **kwargs)\n",
      "C:\\Users\\DHARMIK\\Anaconda3\\lib\\site-packages\\msgpack_numpy.py:184: PendingDeprecationWarning: encoding is deprecated, Use raw=False instead.\n",
      "  return _unpackb(packed, **kwargs)\n",
      "C:\\Users\\DHARMIK\\Anaconda3\\lib\\site-packages\\msgpack_numpy.py:184: PendingDeprecationWarning: encoding is deprecated, Use raw=False instead.\n",
      "  return _unpackb(packed, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "nlp=spacy.load('en') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd='C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = 350\n",
    "duration = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noun(x):\n",
    "    nounlist=[]\n",
    "    for token in x:\n",
    "        if token.pos_=='NOUN':\n",
    "            nounlist.append(token.text)\n",
    "    return nounlist\n",
    "def adj(x):\n",
    "   adjlist=[]\n",
    "   for token in x:\n",
    "       if token.pos_=='ADJ':\n",
    "           adjlist.append(token.text)\n",
    "   return adjlist\n",
    "def verb(x):\n",
    "    verblist=[]\n",
    "    for token in x:\n",
    "        if token.pos_=='VERB':\n",
    "            verblist.append(token.text)\n",
    "    return verblist\n",
    "#query = str('start mozilla')       #converting speech to text using speech_to_text API \n",
    "\n",
    "apps=[]\n",
    "def start_app(app_name):\n",
    "    try:\n",
    "        app=Application().start(app_name)\n",
    "        apps.append(app)\n",
    "    \n",
    "    except:\n",
    "        with open(\"paths.txt\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    line=re.split(\"-\",line,1)\n",
    "                    app_path = line[1][:-1] + app_name\n",
    "                    #print(app_path)\n",
    "                    app=Application().start(app_path + \" --renderer-force-accessibility\")\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "def user_single_click(text):\n",
    "    time.sleep(0.5)\n",
    "    img = PIL.ImageGrab.grab()\n",
    "    #imgplot = plt.imshow(img)\n",
    "    data=pytesseract.image_to_data(img)\n",
    "\n",
    "    data=data.split()\n",
    "    #print(data)\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if ' '.join(text) in data[i].lower():\n",
    "            print(\"Match Found\")\n",
    "            #coord_x = int(data[i-5]) + int(data[i-3]/2)\n",
    "            #coord_y = int(data[i-4]) + int(data[i-2]/2)\n",
    "            coord_x = int(data[i-5]) + int(int(data[i-3])/2)\n",
    "            coord_y = int(data[i-4]) + int(int(data[i-2])/2)\n",
    "            mouse.click(button=\"left\",coords=(coord_x,coord_y))\n",
    "            print(\"Mouse Clicked at: (\" ,coord_x,\",\", coord_y,\")\")\n",
    "            break\n",
    "        \n",
    "def user_double_click(text):\n",
    "    time.sleep(0.5)\n",
    "    img = PIL.ImageGrab.grab()\n",
    "    #imgplot = plt.imshow(img)\n",
    "    data=pytesseract.image_to_data(img)\n",
    "\n",
    "    data=data.split()\n",
    "    #print(data)\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if ' '.join(text) in data[i].lower():\n",
    "            print(\"Match Found\")\n",
    "            #coord_x = int(data[i-5]) + int(data[i-3]/2)\n",
    "            #coord_y = int(data[i-4]) + int(data[i-2]/2)\n",
    "            coord_x = int(data[i-5]) + int(int(data[i-3])/2)\n",
    "            coord_y = int(data[i-4]) + int(int(data[i-2])/2)\n",
    "            mouse.double_click(button=\"left\",coords=(coord_x,coord_y))\n",
    "            print(\"Double Clicked at: (\" ,coord_x,\",\", coord_y,\")\")\n",
    "            break\n",
    "        \n",
    "def wait(text):\n",
    "    for i in range(len(text)):\n",
    "            if text[i]=='seconds' or text[1]=='second':\n",
    "                wait_time = int(text[i-1])\n",
    "                print(\"Waiting...\")\n",
    "                if(wait_time>5):\n",
    "                    time.sleep(wait_time-5)\n",
    "while True:\n",
    "    winsound.Beep(frequency, duration)\n",
    "    #time.sleep(1)\n",
    "    query = str(speech.press_record())       #converting speech to text using speech_to_text API \n",
    "    #query=input(\"Enter Command (Type exit to quit): \")\n",
    "    if query.lower()=='exit':\n",
    "        break\n",
    "    else:\n",
    "        print(query) \n",
    "    \n",
    "    doc=nlp(query)\n",
    "    \n",
    "    if not noun(doc):\n",
    "        pass\n",
    "    else:\n",
    "        name=noun(doc)[0]\n",
    "    if not adj(doc):\n",
    "        pass\n",
    "    else:\n",
    "        task=adj(doc)[0]\n",
    "      \n",
    "    if not verb(doc):\n",
    "        pass\n",
    "    else:\n",
    "        do=verb(doc)[0]\n",
    "    \n",
    "    words=[word.text.lower() for word in doc if word.is_stop==False]\n",
    "    words=list(words)\n",
    "    #verbs, obj = words[0], ' '.join(words[1:])\n",
    "    verbs, obj = words[0], words[1:]\n",
    "    print(words)\n",
    "    print(\"Verb: \", verbs, \" Obj: \", obj)\n",
    "#if float(similarity_start)>0.5:\n",
    "    if verbs=='start' or verbs=='open' or verbs=='launch':\n",
    "        for x in obj:\n",
    "            start_app(x)\n",
    "    #elif float(similarity_click)>0.5:\n",
    "    elif verbs=='click':\n",
    "        user_single_click(obj)\n",
    "    elif verbs==\"double\" or verb=='doubleclick':\n",
    "        user_double_click(obj[1:])\n",
    "    elif verbs=='wait':\n",
    "        wait(obj)\n",
    "    \n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "open Chrome\n"
     ]
    }
   ],
   "source": [
    "query = str(speech.press_record())       #converting speech to text using speech_to_text API \n",
    "\n",
    "print(query) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n"
     ]
    }
   ],
   "source": [
    "list_for_pause=[]\n",
    "query=nlp(str(speech.press_record()))\n",
    "for token in query:\n",
    "    if token.text=='wait'\n",
    "def takeApause(x):\n",
    "    if x.text=='wait':\n",
    "        print('awere')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awere\n"
     ]
    }
   ],
   "source": [
    "for token in query:\n",
    "    takeApause(token)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talking\n",
      "############\n",
      "speak again\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-e72562174a86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Start talking'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0maudio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    650\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m                 \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# reached end of the stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m                 \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r=sr.Recognizer()\n",
    "keyword='Scooby'\n",
    "with sr.Microphone() as source:\n",
    "    print('Start talking')\n",
    "    while True:\n",
    "        audio=r.listen(source)\n",
    "        try:\n",
    "            text=r.recognize_google(audio)\n",
    "            if keyword.lower() in text.lower():\n",
    "                print('############')\n",
    "        except Exception as e:\n",
    "            print('speak again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
